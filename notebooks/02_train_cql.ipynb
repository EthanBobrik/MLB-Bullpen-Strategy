{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ce5da68",
   "metadata": {},
   "source": [
    "# RL CQL Training\n",
    "\n",
    "This notebook:\n",
    "1. Loads offline RL tensors from `data/processed/rl_tensors_*.npz`\n",
    "2. Loads CQL hyperparameters from `configs/model.yaml` and `configs/training.yaml`\n",
    "3. Trains a Conservative Q-Learning (CQL) model using `src/rl/cql.py::train_cql`\n",
    "4. Saves the trained model to `models/`\n",
    "5. Runs offline evaluation using `src/ope/offline_eval.py`:\n",
    "    - Mean Squared TD Error (MSTE)\n",
    "    - Direct Q-based value estimate of greedy policy\n",
    "    - Action agreement with logged (behavior) policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06d6cfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy<2.0 in /Users/matthewsaccone/Desktop/MLB-Bullpen-Strategy/.venv/lib/python3.11/site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"numpy<2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c244b60",
   "metadata": {},
   "source": [
    "## 1. Imports & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4509a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /Users/matthewsaccone/Desktop/MLB-Bullpen-Strategy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "PROJECT_ROOT = Path(os.getcwd()).resolve().parent\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "713420d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rl.cql import build_config_from_yamls, train_cql, BullpenOfflineDataset\n",
    "\n",
    "from src.ope.offline_eval_cql import (\n",
    "    OfflineEvalConfig,\n",
    "    load_model_and_dataset,\n",
    "    evaluate_td_error_full_mse,\n",
    "    direct_policy_value_estimate,\n",
    "    compute_action_agreement,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f3e2ab",
   "metadata": {},
   "source": [
    "## 2. Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6264431f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL tensors: /Users/matthewsaccone/Desktop/MLB-Bullpen-Strategy/data/processed/rl_tensors_2022_2023.npz\n",
      "Model config: /Users/matthewsaccone/Desktop/MLB-Bullpen-Strategy/configs/model.yaml\n",
      "Training config: /Users/matthewsaccone/Desktop/MLB-Bullpen-Strategy/configs/training.yaml\n",
      "Model output: /Users/matthewsaccone/Desktop/MLB-Bullpen-Strategy/models/cql_bullpen_2022_2023.pt\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "PROC_DIR = DATA_DIR / \"processed\"\n",
    "CONFIG_DIR = PROJECT_ROOT / \"configs\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "YEAR_TAG = \"2022_2023\"  # must match 01_build_dataset YEARS range\n",
    "RL_TENSORS_PATH = PROC_DIR / f\"rl_tensors_{YEAR_TAG}.npz\"\n",
    "MODEL_CFG_PATH = CONFIG_DIR / \"model.yaml\"\n",
    "DATA_CFG_PATH = PROJECT_ROOT / \"configs/data.yaml\"\n",
    "TRAIN_CFG_PATH = CONFIG_DIR / \"training.yaml\"\n",
    "MODEL_OUT_PATH = MODELS_DIR / f\"cql_bullpen_{YEAR_TAG}.pt\"\n",
    "\n",
    "print(\"RL tensors:\", RL_TENSORS_PATH)\n",
    "print(\"Model config:\", MODEL_CFG_PATH)\n",
    "print(\"Training config:\", TRAIN_CFG_PATH)\n",
    "print(\"Model output:\", MODEL_OUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e98fca4",
   "metadata": {},
   "source": [
    "## 3. Load Dataset & Build Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66315457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CQLConfig(device='cpu', seed=42, input_dim=None, hidden_size=256, num_layers=3, dropout=0.05, num_actions=11, gamma=0.99, lr=0.0005, batch_size=512, max_steps=30, log_interval=200, target_update_interval=5000, tau=0.005, cql_alpha=1.0, cql_min_q_weight=None, cql_temp=1.0, l2_reg=1e-06, checkpoint_dir='checkpoints/', checkpoint_name='cql_model.pth', use_wandb=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "cfg = build_config_from_yamls(\n",
    "    model_yaml=str(MODEL_CFG_PATH),\n",
    "    training_yaml=str(TRAIN_CFG_PATH),\n",
    "    data_yaml=str(DATA_CFG_PATH),     # real YAML only\n",
    "    env_yaml=None,\n",
    "    inference_yaml=None\n",
    ")\n",
    "\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65154568",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CQLConfig' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ds = BullpenOfflineDataset(\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m, rl_tensors_path=RL_TENSORS_PATH)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDataset size:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(ds))\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mState dim:\u001b[39m\u001b[33m\"\u001b[39m, ds.state_dim)\n",
      "\u001b[31mAttributeError\u001b[39m: 'CQLConfig' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "ds = BullpenOfflineDataset(\n",
    "    RLDatasetConfig(\n",
    "        data_path=cfg.data.data_path,\n",
    "        device=device,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Dataset size:\", len(ds))\n",
    "print(\"State dim:\", ds.state_dim)\n",
    "print(\"Num actions:\", ds.num_actions)\n",
    "print(\"H (next hitters window):\", ds.H)\n",
    "print(\"R (max relievers per team):\", ds.R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40643533",
   "metadata": {},
   "source": [
    "## 4. Train CQL Model\n",
    "\n",
    "This calls `train_cql(cfg)`, which:\n",
    " - loads `BullpenOfflineDataset`\n",
    " - trains Conservative Q-Learning\n",
    " - logs TD-error periodically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29800c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "cql_model = train_cql(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b36cdf1",
   "metadata": {},
   "source": [
    "## 5. Save trained model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637219a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cql_model.state_dict(), MODEL_OUT_PATH)\n",
    "MODEL_OUT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0184f3e0",
   "metadata": {},
   "source": [
    "## 6. Offline Policy Evaluation (OPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ca742",
   "metadata": {},
   "outputs": [],
   "source": [
    "ope_cfg = OfflineEvalConfig(\n",
    "    model_config_path=MODEL_CFG_PATH,\n",
    "    model_path=MODEL_OUT_PATH,\n",
    "    tensors_path=RL_TENSORS_PATH,\n",
    "    device=device,\n",
    "    batch_size=2048,\n",
    "    gamma=cfg.training.gamma,\n",
    ")\n",
    "\n",
    "eval_model, eval_ds, eval_loader = load_model_and_dataset(ope_cfg)\n",
    "\n",
    "print(\"Eval dataset size:\", len(eval_ds))\n",
    "print(\"State dim:\", eval_ds.state_dim)\n",
    "print(\"Num actions:\", eval_ds.num_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0776f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Mean Squared TD Error (MSTE)\n",
    "mste = evaluate_td_error_full_mse(\n",
    "    model=eval_model,\n",
    "    loader=eval_loader,\n",
    "    gamma=ope_cfg.gamma,\n",
    "    device=ope_cfg.device,\n",
    ")\n",
    "print(f\"Mean Squared TD Error (MSTE): {mste:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5295115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Direct Q-based value estimate\n",
    "dm_value = direct_policy_value_estimate(\n",
    "    model=eval_model,\n",
    "    loader=eval_loader,\n",
    "    device=ope_cfg.device,\n",
    ")\n",
    "print(f\"Direct Q-based value estimate (V(pi_greedy)): {dm_value:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58582f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Action agreement with logged policy\n",
    "agreement = compute_action_agreement(\n",
    "    model=eval_model,\n",
    "    loader=eval_loader,\n",
    "    device=ope_cfg.device,\n",
    ")\n",
    "print(f\"Action agreement (logged vs greedy): {agreement:.3%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a5d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Summary\n",
    "print(\"========= FINAL CQL EVALUATION RESULTS =========\")\n",
    "print(f\"TD Error (MSTE):              {mste:.6f}\")\n",
    "print(f\"Direct Q-based V(pi_greedy):  {dm_value:.6f}\")\n",
    "print(f\"Action agreement rate:        {agreement:.3%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
