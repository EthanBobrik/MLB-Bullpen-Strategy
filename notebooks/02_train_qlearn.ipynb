{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular Q-Learning Training Notebook\n",
    "This notebook trains and evaluates the tabular Q-learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /Users/scottyang/MLB-Bullpen-Strategy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "# Set project root\n",
    "PROJECT_ROOT = Path(os.getcwd()).resolve().parent\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_tabular_q_config' from 'src.rl.tabular_q_agent' (/Users/scottyang/MLB-Bullpen-Strategy/src/rl/tabular_q_agent.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtabular_q_agent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     load_tabular_q_config,\n\u001b[1;32m      3\u001b[0m     train_tabular_q_agent,\n\u001b[1;32m      4\u001b[0m     TabularOfflineDataset,\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_tabular_q_config' from 'src.rl.tabular_q_agent' (/Users/scottyang/MLB-Bullpen-Strategy/src/rl/tabular_q_agent.py)"
     ]
    }
   ],
   "source": [
    "from src.rl.tabular_q_agent import (\n",
    "    load_tabular_q_config,\n",
    "    train_tabular_q_agent,\n",
    "    TabularOfflineDataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL tensors: /Users/scottyang/MLB-Bullpen-Strategy/data/processed/rl_tensors_2022_2023.npz\n",
      "Model config: /Users/scottyang/MLB-Bullpen-Strategy/configs/model.yaml\n",
      "Model output: /Users/scottyang/MLB-Bullpen-Strategy/models/tabular_q_2022_2023.npy\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "PROC_DIR = DATA_DIR / \"processed\"\n",
    "CONFIG_DIR = PROJECT_ROOT / \"configs\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Must match your dataset name\n",
    "YEAR_TAG = \"2022_2023\"\n",
    "\n",
    "RL_TENSORS_PATH = PROC_DIR / f\"rl_tensors_{YEAR_TAG}.npz\"\n",
    "MODEL_CFG_PATH = CONFIG_DIR / \"model.yaml\"\n",
    "MODEL_OUT_PATH = MODELS_DIR / f\"tabular_q_{YEAR_TAG}.npy\"\n",
    "\n",
    "print(\"RL tensors:\", RL_TENSORS_PATH)\n",
    "print(\"Model config:\", MODEL_CFG_PATH)\n",
    "print(\"Model output:\", MODEL_OUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Load Dataset & Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'load_tabular_q_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing device:\u001b[39m\u001b[38;5;124m\"\u001b[39m, device)\n\u001b[0;32m----> 4\u001b[0m train_cfg \u001b[38;5;241m=\u001b[39m load_tabular_q_config(\n\u001b[1;32m      5\u001b[0m     model_config_path\u001b[38;5;241m=\u001b[39mMODEL_CFG_PATH,\n\u001b[1;32m      6\u001b[0m     data_path\u001b[38;5;241m=\u001b[39mRL_TENSORS_PATH,\n\u001b[1;32m      7\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m train_cfg\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_tabular_q_config' is not defined"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "train_cfg = load_tabular_q_config(\n",
    "    model_config_path=MODEL_CFG_PATH,\n",
    "    data_path=RL_TENSORS_PATH,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "train_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TabularOfflineDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ds \u001b[38;5;241m=\u001b[39m TabularOfflineDataset(\n\u001b[1;32m      2\u001b[0m     data_path\u001b[38;5;241m=\u001b[39mtrain_cfg\u001b[38;5;241m.\u001b[39mdata_path,\n\u001b[1;32m      3\u001b[0m     device\u001b[38;5;241m=\u001b[39mtrain_cfg\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset size:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(ds))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNum actions:\u001b[39m\u001b[38;5;124m\"\u001b[39m, ds\u001b[38;5;241m.\u001b[39mnum_actions)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TabularOfflineDataset' is not defined"
     ]
    }
   ],
   "source": [
    "ds = TabularOfflineDataset(\n",
    "    data_path=train_cfg.data_path,\n",
    "    device=train_cfg.device,\n",
    ")\n",
    "\n",
    "print(\"Dataset size:\", len(ds))\n",
    "print(\"Num actions:\", ds.num_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save trained model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tabular_agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tabular_agent\u001b[38;5;241m.\u001b[39msave(MODEL_OUT_PATH)\n\u001b[1;32m      2\u001b[0m MODEL_OUT_PATH\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tabular_agent' is not defined"
     ]
    }
   ],
   "source": [
    "tabular_agent.save(MODEL_OUT_PATH)\n",
    "MODEL_OUT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Offline TD error (Bellman Residual)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tabular_agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m         n \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m total \u001b[38;5;241m/\u001b[39m n\n\u001b[0;32m---> 19\u001b[0m mste \u001b[38;5;241m=\u001b[39m tabular_td_error(tabular_agent, ds, gamma\u001b[38;5;241m=\u001b[39mtrain_cfg\u001b[38;5;241m.\u001b[39mgamma)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Squared TD Error:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mste)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tabular_agent' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def tabular_td_error(agent, ds, gamma):\n",
    "    total = 0\n",
    "    n = 0\n",
    "    for i in range(len(ds)):\n",
    "        s, a, r, ns, done, mask = ds[i]\n",
    "\n",
    "        s_key = agent._s(s)\n",
    "        ns_key = agent._s(ns)\n",
    "\n",
    "        q_sa = agent.Q[s_key][a]\n",
    "        target = r if done else (r + gamma * np.max(agent.Q[ns_key]))\n",
    "\n",
    "        total += (q_sa - target)**2\n",
    "        n += 1\n",
    "    return total / n\n",
    "\n",
    "mste = tabular_td_error(tabular_agent, ds, gamma=train_cfg.gamma)\n",
    "print(\"Mean Squared TD Error:\", mste)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Direct Q-Based Estimate of Greedy Policy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tabular_agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m         vals\u001b[38;5;241m.\u001b[39mappend(v)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(vals)\n\u001b[0;32m---> 13\u001b[0m dm_value \u001b[38;5;241m=\u001b[39m tabular_direct_value(tabular_agent, ds)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirect Q-based greedy value:\u001b[39m\u001b[38;5;124m\"\u001b[39m, dm_value)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tabular_agent' is not defined"
     ]
    }
   ],
   "source": [
    "def tabular_direct_value(agent, ds):\n",
    "    vals = []\n",
    "    for i in range(len(ds)):\n",
    "        s, a, r, ns, d, mask = ds[i]\n",
    "\n",
    "        s_key = agent._s(s)\n",
    "        q = agent.Q[s_key].copy()\n",
    "        q[~mask] = -1e9\n",
    "        v = np.max(q)  # V_pi(s) = max_a Q(s,a)\n",
    "        vals.append(v)\n",
    "    return np.mean(vals)\n",
    "\n",
    "dm_value = tabular_direct_value(tabular_agent, ds)\n",
    "print(\"Direct Q-based greedy value:\", dm_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Action agreement with logged policy\n",
    "\n",
    "How often does the greedy Tabular Q-Learning action (respecting availability mask) match the logged (historical) action from the dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tabular_agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m         matches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(greedy_a \u001b[38;5;241m==\u001b[39m a_logged)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m matches \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(ds)\n\u001b[0;32m---> 10\u001b[0m agreement \u001b[38;5;241m=\u001b[39m tabular_action_agreement(tabular_agent, ds)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction agreement with MLB policy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magreement\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tabular_agent' is not defined"
     ]
    }
   ],
   "source": [
    "def tabular_action_agreement(agent, ds):\n",
    "    matches = 0\n",
    "    for i in range(len(ds)):\n",
    "        s, a_logged, _, _, _, mask = ds[i]\n",
    "        greedy_a = agent.act(s, mask)\n",
    "\n",
    "        matches += int(greedy_a == a_logged)\n",
    "    return matches / len(ds)\n",
    "\n",
    "agreement = tabular_action_agreement(tabular_agent, ds)\n",
    "print(f\"Action agreement with MLB policy: {agreement:.3%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 9. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== FINAL TABULAR Q EVALUATION ===========\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mste' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=========== FINAL TABULAR Q EVALUATION ===========\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTD Error (MSTE):              \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmste\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirect value V(pi_greedy):    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdm_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction agreement rate:        \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magreement\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mste' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"=========== FINAL TABULAR Q EVALUATION ===========\")\n",
    "print(f\"TD Error (MSTE):              {mste:.6f}\")\n",
    "print(f\"Direct value V(pi_greedy):    {dm_value:.6f}\")\n",
    "print(f\"Action agreement rate:        {agreement:.3%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
